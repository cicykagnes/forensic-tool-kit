# -*- coding: utf-8 -*-
"""faceNET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10y-KgstPoV-2ZGXMqtUlafJxzAdXW2qp
"""

from google.colab import drive
drive.mount('/content/drive')

pip install mtcnn

import os
import tensorflow as tf
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import matplotlib.image as img
import mtcnn
import matplotlib
from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate
from keras.layers.core import Lambda, Flatten, Dense
from keras.layers.normalization import BatchNormalization
from keras.layers.pooling import MaxPooling2D, AveragePooling2D
from keras.models import Model
from keras import backend as K
import utils
from utils import LRN2D

class LoadDataset():
  
  def __init__(self):
    
    self.train_path = "/content/drive/MyDrive/CelebDataSet/data/train/"
    self.test_path   = "/content/drive/MyDrive/celebDataSet/data/val/"
    self.yarr , self.Y , self.xdict = [] , [] , dict()

    for i in os.listdir(self.train_path):
      self.yarr.append(i) 
    for i in self.yarr:
      self.xdict[i]=[]

    for i in os.listdir(self.train_path):
      for j in os.listdir(self.train_path+i):
        testImage = img.imread(self.train_path + i+ "/" + j )
        self.xdict[i].append(testImage)

    for i in self.xdict.keys():
      for j in range(len(self.xdict[i])):
        self.Y.append(i)
    print(self.xdict.keys())

  def ReturnDataset(self):
    
    return self.xdict , self.yarr , self.Y

  def Imshow(self,name,number):
    
    plt.imshow(self.xdict[name][number])
    plt.show()
  
  def MTCNN(self , name , number):
    
    detector = mtcnn.MTCNN()
    faces = detector.detect_faces(self.xdict[name][number])
    plt.imshow(self.xdict[name][number])
    
    def draw_facebox(result_list):  
      ax = plt.gca()
      STANDARD_SHAPE = 170
      for result in faces:
        x, y, width, height = result['box']
        print(f"-----before croping--{width , height}------")
        rect = plt.Rectangle((x, y), width, height, fill=False, color='green')
        ax.add_patch(rect)
        plt.show()
        
        print("-----after croping----150 X 150----")
        im = Image.fromarray(self.xdict[name][number])
        im = im.crop((x , y , x+STANDARD_SHAPE , y+STANDARD_SHAPE))
        plt.imshow(im)
      return im
    draw_facebox(faces)
  return im

ld = LoadDataset()
xdict , yarr , Y = ld.ReturnDataset()
for i in xdict:
  for k in range(len(xdict[i])):
      im = ld.MTCNN(i , k)
      xdict[i][k] = im

class faceNet():
    def __init__(self):
      pass
    def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):
      
      pairwise_dist = _pairwise_distances(embeddings, squared=squared)
      mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)
      mask_anchor_positive = tf.to_float(mask_anchor_positive)
      anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)
      hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)
      mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)
      mask_anchor_negative = tf.to_float(mask_anchor_negative)
      max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)
      anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)
      hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)
      triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)
      triplet_loss = tf.reduce_mean(triplet_loss)
      return triplet_loss
    
    def modelTrain(self):
      
      optmi = tf.train.adadelta(learning_rate=0.001,rho=0.95,epsilon=1e-07,name='Adadelta')
      _ , loss = optim.minimize(batch_hard_triplet_loss)
    
    def model_Train_Test_Save(self):
      pass



